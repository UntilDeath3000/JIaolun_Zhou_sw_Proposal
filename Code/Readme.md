# Dataset Acquisition and Structuring (qabot\dataclean.py): The initial phase involves sourcing a robust dataset from the WebQA.v1.0 repository, which is recognized for its extensive collection of real-world question-answer pairs. This step entails meticulous parsing of the raw data to build a structured Q&A dataset that adheres to the specific requirements of the intended model. The process may include removing irrelevant or redundant information, normalizing text formatting, categorizing questions by type, and ensuring that each entry has a corresponding well-formed question and answer pair.

Deactivated Words Filtering (qabot\create_qa_dict.py): A crucial aspect of preprocessing is refining the dataset through the filtration of deactivated words. These are typically stop words, punctuation, or any terms identified as noise or not contributing significantly to the semantic meaning within the context of a Q&A system. The create_qa_dict.py script meticulously scans all instances of data, applying a pre-defined list of deactivated words or using automated methods to identify such terms. By doing so, it enhances the signal-to-noise ratio of the content, focusing the model's attention on more informative keywords and phrases. This filtering process also includes handling special cases like contractions, abbreviations, and domain-specific jargon, ultimately refining the dataset to be more conducive for machine learning models to ingest and learn effectively from.
